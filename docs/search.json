[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Introduction\n\nHello! My name is Nanami Tsuchiyama, I’m an MSc Urban Spatial Science student at UCL CASA. I was born and brought up in Tokyo, Japan for most of my life. This is my fifth year in London.\nI studied Geography and Social Data Science for my undergraduate degree at the Department of Geography at UCL, where I developed interests in urban geography and quantitative analysis. In my second year of undergraduate studies, I took the module “Understanding Cities and their Spatial Cultures”, which was run by academics at CASA. I was introduced to the different areas of research conducted at the department which I found very interesting and it motivated me to study this degree.\nI decided to take this module (CASA0023) because I was interested in how remote sensing may be used to collect data on informal settlements in the Global South, where traditional forms of data is scarce. For my dissertation in my undergraduate degree I wrote about Food Deserts in Johannesburg, South Africa, where I faced challenges collecting data around informal areas and economy. These limitations led me to literature about analysis of socio-economic conditions based on satellite images. Through this module I hope to learn how remote sensing works, and develop a better understanding of how these type of analysis is conducted."
  },
  {
    "objectID": "intro.html#summary",
    "href": "intro.html#summary",
    "title": "Week 1",
    "section": "Summary",
    "text": "Summary\n\n1. What is remote sensing?\nElectro"
  },
  {
    "objectID": "intro.html#application",
    "href": "intro.html#application",
    "title": "Week 1",
    "section": "Application",
    "text": "Application"
  },
  {
    "objectID": "intro.html#reflection",
    "href": "intro.html#reflection",
    "title": "Week 1",
    "section": "Reflection",
    "text": "Reflection"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Week 2",
    "section": "",
    "text": "This link will take you to the presentation for this week’s learning diary, also available down below."
  },
  {
    "objectID": "week_4.html#summary",
    "href": "week_4.html#summary",
    "title": "Week 4: Policy",
    "section": "Summary",
    "text": "Summary\nYokohama City, located approximately 30-40km away to the south west from the central area of Tokyo, is the capital city of Kanagawa prefecture. With a population of approximately 3.7 million, it is the largest municipality in the country. Yokohama as a port city is known for its leading role in trade, commerce, shipping, shipbuilding internationally, supporting the everyday lives of the Tokyo Metropolitan region (The City of Yokohama Europe Representative Office n.d.).\nForming the Tokyo-Yokohama conurbation, Yokohama city has been identified as urban areas with one of the highest risks of natural disasters due to its high exposure to earthquakes and flood risks (Schwarz, Michael 2014). Based on these identified risks, the Disaster Risk Prevention Plan set by Yokohama has three pillars: measures against earthquakes, measure against floods and storms, and measures against urban disasters (Yokohama City Disaster Prevention Council 2021). Here, we would like to focus on measures against earthquakes, due to its proneness to different types of earthquakes and the large scale damage expected (The City of Yokohama 2019).\nThe existing plan is focused on the actions to be taken for an immediate response (comprised of 177 pages), while there has not been as much attention towards the rehabilitation and recovery of the city (comprised of 30 pages). Within this framework, the reconstruction of the city has been minimum amount of attention, briefly mentioning its plans to consider the areas for specific policy implementation, notify the residents, considering the plans for Yokohoma city as a whole and each area (Yokohama City Disaster Prevention Council 2021). In the action strategy based on this plan set for 2013-2022 comprised of three main goals: minimising damage, suppress confusion in the event of an outbreak and protect the lives of citizens, and support victims and promote early recovery, there was no direct mention of City Reconstruction as a target (The City of Yokohama 2013).\nIn the neighbouring city Tokyo, there have been efforts made for “Pre-reconstruction”, which involves considering in advance the modalities, procedures, and execution system for a rapid and well-planned urban reconstruction and sharing the information with residents and administrative staff (Bureau of Urban Development Tokyo Metropolitan Government 2021). This indicates the importance of having a more well-developed plan for recovery. In addition, in the Sendai Framework for Disaster Risk Reduction, the recovery, rehabilitation and reconstruction phase has been identified as a ‘critical opportunity to build back better’ (United Nations Office for Disaster Risk Reduction n.d.). It also recognises the phase as allowing further disaster risk reduction to be incorporated in the development measures (ibid.). Therefore, it is crucial for Yokohama city to implement policies that allow for an effective recovery which will make the city more prepared for future disaster not just only earthquakes."
  },
  {
    "objectID": "week_4.html#applications",
    "href": "week_4.html#applications",
    "title": "Week 4: Policy",
    "section": "Applications",
    "text": "Applications\nRemote sensing data has been used as a proxy of disaster risk in different phases, such as damage, recovery, resilience, and vulnerability (Ghaffarian, Kerle, and Filatova 2018). Here, we are especially interested in how the data may be used in recovery process. In addition, there are several types of environments where remote-sensing based proxies have been developed (ibid.). This includes physical assessments through investigating built-up aspects, and also non-physical assessments involving economic, social, and natural aspects (ibid.).\nOne of the potential applications of remote sensing applications is by looking at building removal and reconstruction through very high resolution (VHR) images over multiple time periods. The number of reconstructed buildings can show how much progress has been made in the recovery process (Ghaffarian, Kerle, and Filatova 2018). A periodic monitoring of recovery is important to understand the locations where recovery is slow, which will allow for further examination into the reasons for the the delay and implementing targeted measures that tackle the issue. However, it should be noted that while this data may be used for understanding the speed of recovery, investigation into the quality of recovery should be conducted as well, perhaps through field observations (Platt, Brown, and Hughes 2016). This will allow for the assessment of functional recovery.\nAnother potential area of application is looking into spatial connectivity to the central business district, in this case not only the CBD of Yokohama but also Tokyo as it is often considered as a singular urban zone. This involves the usage of satellite imagery for the identification of road networks. According to the study by Contreas et al (2013), spatial connectivity which is measured by variables such as distance and travel time may be considered as a proxy for post-earthquake recovery due to its relationship with the return of economic functioning."
  },
  {
    "objectID": "week_4.html#reflections",
    "href": "week_4.html#reflections",
    "title": "Week 4: Policy",
    "section": "Reflections",
    "text": "Reflections\nResearching into the application of remote sensing data in the field of disaster risk reduction was very informative in terms of what areas have been less researched, which also happen to be perhaps payed less attention in policy. According to Ghaffarian et al (2018), the theme of recovery has been relatively neglected in the area of disaster risk reduction in comparison to areas of damage and vulnerability. In addition, much of the research with remote sensing data particulary through the usage of small aerial drones, a newer platform for satellite imagery have been applied to landslides or other mass movements, particularly within rural environments (Kucharczyk and Hugenholtz 2021). Research around earthquakes and disasters in urban areas in general has been less researched (ibid.). Yokohama pushing forward policies for the usage of remote sensing data for the recovery and reconstruction of the city may become a role model for other cities to follow, and allow for more research in the area.\n\n\n\n\nBureau of Urban Development Tokyo Metropolitan Government. 2021. “Efforts for Pre-Recovery of the City in Preparation for an Earthquake Directly Hitting the Tokyo Metropolitan Area (首都直下地震等に備えた都市の事前復興の取組).” Bureau of Urban Development Tokyo Metropolitan Government. https://www.toshiseibi.metro.tokyo.lg.jp/bunyabetsu/bosai/shuto.html.\n\n\nContreras, Diana, Thomas Blaschke, Stefan Kienberger, and Peter Zeil. 2013. “Spatial Connectivity as a Recovery Process Indicator: The L’Aquila Earthquake.” Technological Forecasting and Social Change 80 (9): 1782–1803.\n\n\nGhaffarian, Saman, Norman Kerle, and Tatiana Filatova. 2018. “Remote Sensing-Based Proxies for Urban Disaster Risk Management and Resilience: A Review.” Remote Sensing 10 (11): 1760.\n\n\nKucharczyk, Maja, and Chris H Hugenholtz. 2021. “Remote Sensing of Natural Hazard-Related Disasters with Small Drones: Global Trends, Biases, and Research Opportunities.” Remote Sensing of Environment 264: 112577.\n\n\nPlatt, Stephen, Daniel Brown, and Martin Hughes. 2016. “Measuring Resilience and Recovery.” International Journal of Disaster Risk Reduction 19: 447–60.\n\n\nSchwarz, Michael. 2014. “Risky Cities: Tokyo.” Zurich: Swiss Re. https://www.swissre.com/dam/jcr:22462410-f30f-46a3-9bc0-4713c5760928/Factsheet_Tokyo-Yokohama_WEB.pdf.\n\n\nThe City of Yokohama. 2013. “Yokohama City Earthquake Disaster Prevention Strategy (横浜市地震防災戦略).” The City of Yokohama. https://www.city.yokohama.lg.jp/kurashi/bousai-kyukyu-bohan/bousai-saigai/bosaikeikaku/keikaku/keikakutou/shinsai.files/jisinbousaisenryaku.pdf.\n\n\n———. 2019. “Estimated Damage in Yokohama City (横浜市の被害想定).” The City of Yokohama. https://www.city.yokohama.lg.jp/kurashi/bousai-kyukyu-bohan/bousai-saigai/wagaya/jishin/higai/higaisoutei.html.\n\n\nThe City of Yokohama Europe Representative Office. n.d. “The Reasons Why Yokohama Is Chosen (横浜が選ばれる理由).” The City of Yokohama Europe Representative Office. Accessed February 14, 2023. https://yokohama-city.de/jp/business-opportunities/.\n\n\nUnited Nations Office for Disaster Risk Reduction. n.d. “What Is the Sendai Framework for Disaster Risk Reduction?” United Nations Office Fot Disaster Risk Reduction. Accessed February 15, 2023. https://www.undrr.org/implementing-sendai-framework/what-sendai-framework.\n\n\nYokohama City Disaster Prevention Council. 2021. “Yokohama City Disaster Prevention Plan Earthquake Countermeasures 2021 (横浜市防災計画震災対策編).” City of Yokohama. https://www.city.yokohama.lg.jp/kurashi/bousai-kyukyu-bohan/bousai-saigai/bosaikeikaku/keikaku/keikakutou/shinsai.files/shinsaitaisaku-all.pdf."
  },
  {
    "objectID": "week_1.html#summary",
    "href": "week_1.html#summary",
    "title": "Week 1: Getting started with remote sensing",
    "section": "Summary",
    "text": "Summary\nFor the first week we covered the following topics in the introductory lecture and practical:\n\nTypes of Sensors\n\nactive\npassive\n\nElectromagnetic Waves\n\nInteraction with the Earth’s surface\nInteraction with the atmosphere\n\nDifferent dimensions of resolution\n\nSpatial Resolution\nSpectral Resolution\nRadiometric Resolution\nTemporal Resolution\n\n\nBelow I try to provide a comprehensive summary of the content we covered, based on works of Brady (2021), Jensen (1996), and Tempfli et al. (2009).\nThe American Society for Photogrametry and Remote Sensing (ASPRS) has defined remote sensing as “the measurement or acquisition of information of some property of an object or phenomenon, by a recording device that is not in physical or intimate contact with the object or phenomenon under study” (Colwell 1983). To understand how remote sensing works, it is crucial for one to learn about electromagnetic radiation. Electromagnetic radiation is a kind of kinetic energy that is produced with the movement of electrically charged particles through space. Electromagnetic radiation consists of two components, an electric field and magnetic field, and it moves back and forth in and changes between the fields in a wave-like fashion.\n\n\n\nElectromagnetic Radiation (Tempfli et al. 2009, 57)\n\n\nThe waves have differing three main different properties of waves\n\nWavelength: “the distance energy travels from a moment of maximum electrical energy until reaching the maximum again”\nAmplitude: “the peak value of the wave”\nFrequency: “the number of cycles of the wave that occur in one second”\n\n\n\n\nCharacteristics of the wave (Tempfli et al. 2009, 58) - lambda = wavelength, alpha = amplitude\n\n\nThe product of the wavelength and frequency is constant, equalling to the speed of light. Electromagnetic spectrum refers to the range of wavelength and frequencies that produces different colours of visible light and non-visible light.\n\n\n\nElectromagnetic Spectrum (Brady 2021)\n\n\nIn remote sensing, data may be collected with passive sensors that collect the electromagnetic radiation sourced from the Sun or other objects on the Earth and then reflected or emitted. It could also be collected using active sensors, such as RADAR and LiDAR, which produce the electromagnetic radiation and detects the reflection. There are a number of dimensions of the data to be considered in this collection process. One of these dimensions is regarding the spectral information and resolution. It is common for sources of remote sensing data to produce multi-band images, which means that the images are composed of multiple bands each comprised of a range of wavelengths on the electromagnetic spectrum. The relationship between the amount of electromagnetic radiation reflected in each of the bands and the biological, chemical, and physical attributes are often modelled. Bands are selected based on their appropriateness for the getting information about these attributes, regarding the maximisation of the background and variable of interest. Other dimensions to be considered are spatial resolution and the temporal resolution. The subject areas where remote sensing data is applied may differ depending on the combination of the values.\n\nSample of Practical Output\nSentinel Data Area of Interest: Yokohama, Kanagawa Japan\n\n\n\nRGB Image\n\n\n\n\n\nScatterplot of band 4 and band 8\n\n\n\nBand 4: red (vegetation absorbs)\nBand 8: Near-infrared (NIR, that vegetation strongly reflects)\n\nhigh values of NIR and low values of red → dense vegetation\nlow values of both red and NIR → wet bare soil."
  },
  {
    "objectID": "week_1.html#application",
    "href": "week_1.html#application",
    "title": "Week 1: Getting started with remote sensing",
    "section": "Application",
    "text": "Application\nHere I will introduce two studies that I have found about the usage of different bands. The first study by Oon et al. (2019) is about the classification of given the issue of the conversion of tropical swamp forests into oil palm agriculture land, and how remote sensing data may be use for the identification of these areas, including whether they are large scale plantations operated by commercial firms, or smaller farms run by individual farmers. The region of interest is the state of Selangor on the west coast of Peninsular Malaysia, and level 2 imagery from Landsat-8 for the four dates of 24 March 2014, 30 March 2015, 29 March 2016 and 17 April 2017 was tests. It calculates three types of vegetation indices: the normalized difference vegetation index (NDVI), enhanced vegetation index (EVI) and soil adjusted vegetation index (SAVI). NDVI and SAVI is calculated with bands 4 (red band) and 5 (near-infrared (NIR) band), and EVI is calculated with bands 3 (blue band), 4 and 5. These indices are used to classify land usage for three categories with different methods: the supervised maximum likelihood (ML), random tree (RT) and support vector machine (SVM) classifier.\n\n\n\nClassified Maps of Multi-temporal Datasets with Different Band Combinations (Oon et al. 2019)\n\n\nThe second study by Yang and Du (2017) is regarding the extraction of water bodies for the monitoring of water resources by devising an enhanced water index. The development of EHI is based on three measures. This includes the first two components of principle components analysis conducted on the six multispectral bands in 30m pixel size from the Landsat 5 Thematic Mapper imagery for 23 September 2011. The third measure is the modified Normalized difference water index (NDWI) which is calculated with TM Band 2 which corresponds to the green band, and TM Band 5 which corresponds to the mid-infrared band (MIR). The accuracy of EHI is tested in comparison to other indices, with the results demonstrating the appropriateness of EHI for extracting water bodies in areas of mixed land usage.\n\n\n\nIndex Images of the Study Area (Yang and Du 2017)\n\n\nThe two studies demonstrate how studies do not only consider the direct usage of the remote sensing data from different bands at various combinations of spatial and temporal resolutions but how the different bands are combined together for the calculation of indices to develop or classification for an enhanced understanding."
  },
  {
    "objectID": "week_1.html#reflection",
    "href": "week_1.html#reflection",
    "title": "Week 1: Getting started with remote sensing",
    "section": "Reflection",
    "text": "Reflection\nIt was interesting how the values of different bands are combined to develop different types of indices and how these are developed on the base on the raw data that has been collected by the sensors. Moreover, these indices are not just done with their calculation, but seem to used for further analysis of the data. The range of things we can do with remote sensing data is much wider than I have expected. The usage of the SNAP application and raster data in Rstudio is something I am not familiar with and would like to learn more about. However, in the lecture it was mentioned that there are limitations in conducting analysis with R, so I look forward to learn about new platforms as well.\n\n\n\n\nBrady, Maria. 2021. “Remote Sensing for Dummies.” https://storymaps.arcgis.com/stories/cb1577b0f5bc485c974b4ea19d52282d.\n\n\nColwell, Robert N. 1983. “Manual of Remote Sensing.”\n\n\nJensen, John R et al. 1996. Introductory Digital Image Processing: A Remote Sensing Perspective. Ed. 2. Prentice-Hall Inc.\n\n\nOon, Aslinda, Helmi Zulhaidi Mohd Shafri, Alex Mark Lechner, and Badrul Azhar. 2019. “Discriminating Between Large-Scale Oil Palm Plantations and Smallholdings on Tropical Peatlands Using Vegetation Indices and Supervised Classification of LANDSAT-8.” International Journal of Remote Sensing 40 (19): 73127328.\n\n\nTempfli, Klaus, GCe Huurneman, WHe Bakker, Lucas LF Janssen, WF Feringa, ASM Gieske, KA Grabmaier, et al. 2009. Principles of Remote Sensing: An Introductory Textbook. International Institute for Geo-Information Science; Earth Observation.\n\n\nYang, Jason, and Xianrong Du. 2017. “An Enhanced Water Index in Extracting Water Bodies from Landsat TM Imagery.” Annals of GIS 23 (3): 141148."
  },
  {
    "objectID": "week_2.html",
    "href": "week_2.html",
    "title": "Week 2: Portfolio",
    "section": "",
    "text": "This link will take you to the presentation for this week’s learning diary, also available to see down below."
  },
  {
    "objectID": "week_1.html",
    "href": "week_1.html",
    "title": "1  Week 1",
    "section": "",
    "text": "The American Society for Photogrametry and Remote Sensing (ASPRS) has defined remote sensing as “the measurement or acquisition of information of some property of an object or phenomenon, by a recording device that is not in physical or intimate contact with the object or phenomenon under study (Colwell, 1983) . To understand how remote sensing works, it is crucial for one to learn about electromagnetic radiation. Electromagnetic radiation is a kind of kinetic energy that is produced with the movement of electrically charged particles through space” (citation). Electromagnetic radiation consists of two components, an electric field and magnetic field, and it moves back and forth in and changes between the fields in a wave-like fashion ().\nThe waves have differing three main different properties of waves - Wavelength: “the distance energy travels from a moment of maximum electrical energy until reaching the maximum again” - Amplitude: “the peak value of the wave” - Frequency: “the number of cycles of the wave that occur in one second”. The product of the wavelength and frequency is constant, equalling to the speed of light (ibid.). Electromagnetic spectrum refers to the range of wavelength and frequencies that produces different colours of visible light and non-visible light ().\nIn remote sensing, data may be collected with passive sensors that collect the electromagnetic radiation sourced from the Sun or other objects on the Earth and then reflected or emitted. It could also be collected using active sensors, such as RADAR and LiDAR, which produce the electromagnetic radiation and detects the reflection (). There are a number of dimensions of the data to be considered in this collection process. One of these dimensions is regarding the spectral information and resolution. It is common for sources of remote sensing data to produce multi-band images, which means that the images are composed of multiple bands each comprised of a range of wavelengths on the electromagnetic spectrum (). The relationship between the amount of electromagnetic radiation reflected in each of the bands and the biological, chemical, and physical attributes are often modelled (). Bands are selected based on their appropriateness for the getting information about these attributes, regarding the maximisation of the background and variable of interest. Other dimensions to be considered are spatial resolution and the temporal resolution. The subject areas where remote sensing data is applied may differ depending on the combination of the values.\nHere I will introduce two studies that I have found. The first study by Oon et al. (2019) is about the classification of given the issue of the conversion of tropical swamp forests into oil palm agriculture land, and how remote sensing data may be use for the identification of these areas, including whether they are large scale plantations operated by commercial firms, or smaller farms run by individual farmers. The region of interest is the state of Selangor on the west coast of Peninsular Malaysia, and level 2 imagery from Landsat-8 for the four dates of 24 March 2014, 30 March 2015, 29 March 2016 and 17 April 2017 was tests. It calculates three types of vegetation indices: the normalized difference vegetation index (NDVI), enhanced vegetation index (EVI) and soil adjusted vegetation index (SAVI). NDVI and SAVI is calculated with bands 4 (red band) and 5 (near-infrared (NIR) band), and EVI is calculated with bands 3 (blue band), 4 and 5. These indices are used to classify land usage for three categories with different methods: the supervised maximum likelihood (ML), random tree (RT) and support vector machine (SVM) classifier. The second study by Yang and Du (2017) is regarding the extraction of water bodies for the monitoring of water resources by devising an enhanced water index. The development of EHI is based on three measures. This includes the first two components of principle components analysis conducted on the six multispectral bands in 30m pixel size from the Landsat 5 Thematic Mapper imagery for 23 September 2011. The third measure is the modified Normalized difference water index (NDWI) which is calculated with TM Band 2 which corresponds to the green band, and TM Band 5 which corresponds to the mid-infrared band (MIR). The accuracy of EHI is tested in comparison to other indices, with the results demonstrating the appropriateness of EHI for extracting water bodies in areas of mixed land usage. The two studies demonstrate how studies do not only consider the direct usage of the remote sensing data from different bands at various combinations of spatial and temporal resolutions but how the different bands are combined together for the calculation of indices to develop or classification for an enhanced understanding.\nLearning about how remote sensing works It was interesting how the values of different bands are combined develop different types of indices and how these are developed on the base of the top."
  },
  {
    "objectID": "week_7.html#summary",
    "href": "week_7.html#summary",
    "title": "Week 7: Classification II",
    "section": "Summary",
    "text": "Summary\nThis week we went through the following topics in the lecture and the practical:\n\nclassification (continuing from the previous week)\n\npre-classified data\nObject-based image analysis\nSub pixel analysis\n\naccuracy assessment\n\nerror matrix and kappa\nThe trade-off between recall and precision\nF1, ROC curve\nSpatial cross validation\n\n\nFor the summary, I would like to focus on the last topic of “spatial cross validation” in a Q&A format, which is an important aspect to consider in the train-test split for classification methods as one of the ways to consider spatial autocorrelation.\nWhat is Spatial Cross Validation?\n\nThe usage of “spatial partitioning” using k-means clustering to split the observations (points or pixels) into subsets which are not spatially jointed (Brenning, Bangs, and Becker 2018; Lovelace, Nowosad, and Muenchaw 2023)\n\n\n\n\nSpatial Visualisation of testing and training observations for cross validation (Lovelace, Nowosad, and Muenchaw 2023)\n\n\nWhy is it problematic to use the conventional Cross Validation?\n\nTobler’s first law of geography: “Everything is related to everything else, but near things are more related than distant things”\nConventional Cross Validation does not consider spatial autocorrelation between the training and testing points – training observations may hint what may be expected for testing observations, taking away the validity of the approach (Lovelace, Nowosad, and Muenchaw 2023)\n\nHow does Spatial Cross Validation solve this issue?\n\nBias-reduced assessment of the model’s predictive performance – avoids overfitting (Lovelace, Nowosad, and Muenchaw 2023)\nspatially independent data are required for the estimation of unbiased predictive performance and to test generalization capabilities within the image (Lovelace, Nowosad, and Muenchaw 2023)\n\nHow can this be used in classification using a support vector machine (SVM) model?\n\n“tuning” in SVM model (Gareth et al. 2013)\n\nlooking for the best set of “hyperplanes” for the separation into different classes for classification\nexamining “kernels” with specific hyperparameters for the permission of non-linear boundaries between the different classes\n\nselection of the optimal hyperparameters using cross-validation methods - nested-spatial cross validation\n\nsplitting each of the folds into a number of subfolds which are spatially disjointed and create models for each combination of the parameters (Lovelace, Nowosad, and Muenchaw 2023)\n\nparameter “c” (Yildirim 2020)\n\nconsiders the trade off between classifying the training data with high accuracy but low accuracy for the testing data, and avoiding overfitting for the training data but getting miss classified results\nadds penalty for each point which is not correctly classified\n\nlow value: selection of wide margin costing misclassifications\nhigh value: attempt to minimise incorrectly classified observations using a smaller margin\n\n\nparameter “Gamma” (Yildirim 2020)\nManages the distance of influence of a training point within the classified data\n\nLow value: large similarity radius – allows for more observations to be grouped together\nHigh value: small similarity radius – observations need to be within a tightly bounded area to be classified in the same class, may lead to overfitting when value is extremely large\n\n\n\n\n\n\n\nHyperparameter Tuning and Performance Estimation Levels in Cross Validation (Schratz et al. 2019, 114)\n\n\nAre there any other ways with dealing with the same issue?\n\nObject-based, block-based, cluster-based, buffer-based partitioning (Karasiak et al. 2022)\n\nAre there any limitations of spatial cross validation\n\nArgument that spatial cross validation may lead to overly pessimistic results, leading to the underestimation of map results and probability sampling and design-based statistical inference should be used for accuracy assessment instead (Wadoux et al. 2021)"
  },
  {
    "objectID": "week_7.html#application",
    "href": "week_7.html#application",
    "title": "Week 7: Classification II",
    "section": "Application",
    "text": "Application\nThe question which arises is “how exactly can the usage of spatial cross validation influence the result for the context of remote sensing”. This can be considered with the study by Ploton et al. (Ploton et al. 2020) reproduces works mapping aboveground biomass in central Africa (Gabon, Cameroon, Democratic Republic of Congo). Their interest in this topic arises from the fact that previous maps regarding aboveground biomass (AGB) used for the estimation of greenhouse gas emissions and the assessment the relationship between forest carbon and biodiversity, climate and land management pass overly contradict with maps which are produced at smaller scale with higher quality (ibid., p.2). This can be attributed to the spatial autocorrelation of the AGB data up to 120km and also of the environmental variables used for the modelling of AGB variation, demonstrating the violence of the independence of training and testing datasets (ibid., p.2).\n\n\n\nStudy area and Field Data AGB (Ploton et al. 2020)\n\n\n\n\n\nSemivariogram of a) AGB and b) ABB predictors (Ploton et al. 2020)\n\n\nThey use the Random Forest Classification method to predict AGB in several countries – the data used in the classification are listed below\n\nReference data\n\nForget aboveground pixels – based on the Congo basin forest AGB, aggregated at the 1km spatial resolution, pixel exclusion to focus on the forested pixels with a solid level of canopy between 2000 and 2010 (period based on prediction variable of vegetation) and reliable pixel-level estimations of AGB – total of 28225 unique pixels\n\nPrediction (Independent) variable for classification\n\nEnvironmental data\n\nWorldclim2 database (1970-2000) – monthly average statistics of precipitation, temperature (T), solar radiation (SR), water vapor pressure (WP)\nGlobal-PET database – monthly potential evapotranspiration (PET)\nMODIS – statistics of annual cloud cover (CC) frequency\n\n\nVegetation data\nMODIS Collection 6 (2000-2010) – stack of 8-day composite images at 1km spatial resolution\n\nComputation of reflectance mean and standard deviation layer for each band for the calculation of EVI2 and NDII vegetation indices  \n\n\n\n\n\nCross Validation Workflow (Ploton et al. 2020)\n\n\nThe above diagram demonstrates the flow of the methods employed to conduct this comparative analysis. They test three different types of cross-validation (cv) strategies: random k-fold (k=10) cv, spatial k-fold (k=44) cv, and buffered leave-one out cv. Here I will like to focus on the results of the first two strategies. The model based on random k-fold cv gives a R-squared value of 0.53, indicating that more than half of the variation of the observations may be accounted by this model. However, the model based on spatial k-fold value gives a R-squared value of 0.14, which is a much lower value. This indicates that that the random k-fold cv strategy is leading to overfitting, providing statistics which are more optimistic about the model’s predictive power than it should be, confining to what has been discussed in the summary.\n\n\n\nHeat plots of the relationship between observed AGB versus AGB predictions from (a) random k-fold CV and (b) spatial k-fold CV (Ploton et al. 2020)"
  },
  {
    "objectID": "week_7.html#reflection",
    "href": "week_7.html#reflection",
    "title": "Week 7: Classification II",
    "section": "Reflection",
    "text": "Reflection\nDespite learning about machine learning methods and cross validation in other modules, I was not familiar about the issues when employing the method in a spatial context, so it was sort of eye opening for me. Learning about spatial autocorrelation made me aware of the importance of having a critical eye on results I see in papers, on whether their approach has considered the issue of spatial autocorrelation when splitting the data into the testing data and training data. However, it was interesting to find scholars that spatial cross validation is not effective. I think this addresses the importance of considering different approaches and developing a better understanding of what the approach does well in and what may be the limitation in employing the specific method. Furthermore, as I was not able to delve into the results for the buffered leave-one out cv in the to develop a better understanding of how the issue can be considered.\n\n\n\n\nBrenning, Alexander, Donovan Bangs, and Mark Becker. 2018. “RSAGA: SAGA Geoprocessing and Terrain Analysis.” https://cran.r-project.org/web/packages/RSAGA/index.html.\n\n\nGareth, James, Witten Daniela, Hastie Trevor, and Tibshirani Robert. 2013. An Introduction to Statistical Learning: With Applications in R. Spinger.\n\n\nKarasiak, Nicolas, J-F Dejoux, Claude Monteil, and David Sheeren. 2022. “Spatial Dependence Between Training and Test Sets: Another Pitfall of Classification Accuracy Assessment in Remote Sensing.” Machine Learning 111 (7): 2715–40.\n\n\nLovelace, Robin, Jacub Nowosad, and Jannes Muenchaw. 2023. “Statistical Learning.” Geocomputation with R. https://r.geocompx.org/spatial-cv.html.\n\n\nPloton, Pierre, Frédéric Mortier, Maxime Réjou-Méchain, Nicolas Barbier, Nicolas Picard, Vivien Rossi, Carsten Dormann, et al. 2020. “Spatial Validation Reveals Poor Predictive Performance of Large-Scale Ecological Mapping Models.” Nature Communications 11 (1): 4540.\n\n\nSchratz, Patrick, Jannes Muenchow, Eugenia Iturritxa, Jakob Richter, and Alexander Brenning. 2019. “Hyperparameter Tuning and Performance Assessment of Statistical and Machine-Learning Algorithms Using Spatial Data.” Ecological Modelling 406 (August): 109–20. https://doi.org/10.1016/j.ecolmodel.2019.06.002.\n\n\nWadoux, Alexandre MJ-C, Gerard BM Heuvelink, Sytze De Bruin, and Dick J Brus. 2021. “Spatial Cross-Validation Is Not the Right Way to Evaluate Map Accuracy.” Ecological Modelling 457: 109692.\n\n\nYildirim, Soner. 2020. “Hyperparameter Tuning for Support Vector Machines — C and Gamma Parameters.” Towards Data Science. https://towardsdatascience.com/hyperparameter-tuning-for-support-vector-machines-c-and-gamma-parameters-6a5097416167."
  },
  {
    "objectID": "week_3.html#summary",
    "href": "week_3.html#summary",
    "title": "Week 3: Corrections",
    "section": "Summary",
    "text": "Summary\nThis week we went through the following content in the lecture and the practical:\n\nCorrections – the pre-processing of the raw remotely sensed data\n\nGeometric\nAtmospheric\nOrthorectification / Topographic\nRadiometric\n\nData joining and enhancement\n\nFeathering\nImage enhancement\n\n\nHere I will focus on atmospheric correction – it seems that this type of correction is the most common, as most of the results I saw with the Google search of “remote sensing corrections” seemed to deal with atmospheric correction.\nWhy do we need to conduct atmospheric correction? - The figure below demonstrates how atmospheric attenuation is caused\n\n\n\nVarious Paths of Radiance Received by a Remote Sensing System\n\n\nBelow is a mind map of atmospheric correction, based on the lecture materials and the work by Jensen (1996). It puts together the importance of applying the atmospheric correction, and the different methods which can be employed based on the condition of the image and the capability.\n\n\n\nMindmap\n\n\n\nSample code\nperforming relative atmospheric correction in RStudio from the practical\n\nDark Object Subtraction (DOS)\n\npreliminary step: download raw satellite data that comes in the Digital Number (DN) format\n\n\n\nlibrary(terra)\nlibrary(raster)\nlibrary(RStoolbox)\nlibrary(tidyverse)\nlibrary(fs)\nlibrary(rgdal)\n\n## Import meta-data and bands based on MTL file\nmtlFile  <- (\"prac_3/Lsatdata8/LC08_L1TP_175083_20211005_20211013_01_T1_MTL.txt\")\n                        \nmetaData <- readMeta(mtlFile)\n\nlsatMeta  <- stackMeta(metaData)\n\n# surface reflectance with DOS\n\nl8_boa_ref <- radCor(lsatMeta, metaData, method = \"dos\")\n\n#terra::writeRaster(l8_boa_ref, datatype=\"FLT4S\", filename = \"prac_3/Lsatdata8/l8_boa_ref.tif\", format = \"GTiff\", overwrite=TRUE)\n\n# Radiance \n\nlsat_rad <- radCor(lsatMeta, metaData = metaData, method = \"rad\")\n\n#terra::writeRaster(lsat_rad, datatype=\"FLT4S\", filename = \"prac_3/Lsatdata8/lsat_rad.tif\", format = \"GTiff\", overwrite=TRUE)"
  },
  {
    "objectID": "week_3.html#application",
    "href": "week_3.html#application",
    "title": "Week 3: Corrections",
    "section": "Application",
    "text": "Application\nFor the application section, I would like to consider the question “how does conducting atmospheric correction and not perhaps influence the results of remote sensing analysis”. The research conducted by Siregar et al. (2018) may be useful as a case study to consider this. The study is focused on benthic habitat data in the Harapan and Kalapa Islands, Indonesia (survey area in the shallow water area), and aims to compare the object-image classification results with atmospherically corrected and uncorrected image. They have used FLAASH, which is one of the atmospheric radiative transfer models for absolute atmospheric correction. It allows to remove atmospheric attenuation by the acquisition of parameters such as reflectivity, emissivity, surface temperature and physical surface (ibid., p.2). It is equipped with an aerosol and mean value retrieval method based on dark pixel reflectance ratio (ibid., p.2).\nThe remote sensing data is a SPOT-7 multispectral image from 12 June 2016, consisting of 4 multispectral bands (Blue, Green, Red, NIR) with 6m spatial resolution. The reference data for classification is derived from a photo transect technique (April 2017) for 343 observation points (1m×1m), and the class of habitat is based on the benthic component cover in the images.\n\n\n\nRemotely Sensed Image A) Before Atmospheric Correction and B) After Atmospheric Correction (bands 1, 2, 3) (Siregar et al. 2018)\n\n\nThere are two stages to object-image based analysis. The first stage is segmentation, which involves combining neighbouring pixels until the heterogeneity threshold is hit. The image below demonstrates how the differences between the not-corrected and corrected image already arise at this stage. This may because the contrast of objects becomes more enhanced with atmospheric correction (ibid., p.7).\n\n\n\nSegmentation Results with a) Uncorrected Image and B) Corrected Image (bands 1, 2, 3) (Siregar et al. 2018)\n\n\nThe second stage is classification, using a support vector machine algorithm. The classification scheme is based on the proportion of the 8 benthic components. The accuracy of the the classification is tested with overall accuracy (OA), producer accuracy (PA), user accuracy (UA) and the kappa value. It is possible to see that the overall accuracy of the object-based image classification improves with the atmospherically corrected image compared to the non-corrected image.\n\n\n\nClassification Results with Uncorrected Image (Siregar et al. 2018)\n\n\n\n\n\nClassification Results with Corrected Image (Siregar et al. 2018)\n\n\n\n\n\nAccuracy Assessment (Siregar et al. 2018)"
  },
  {
    "objectID": "week_3.html#reflection",
    "href": "week_3.html#reflection",
    "title": "Week 3: Corrections",
    "section": "Reflection",
    "text": "Reflection\nOne of the points I would like to reflect on here refers to the practical, especially regarding the library which is necessary to conduct the atmospheric correction. RStoolbox cannot be installed anymore with the normal procedure due to its removal from the CRAN repository on 2023-02-13. This made me realise the limitations of using RStudio for remote sensing analysis in a way that I didn’t expect. We did learn in the lecture that in many cases this type of correction has been pre-applied to the image for the usage some platforms. However, I think it is important that we know how these corrections are supposed to be applied for the appropriate usage of the data and how it might influence the results, as the study by Siregar et al. (2018) have shown. Furthermore, I will like to learn more about the suitability of different types of atmospheric correction in various contexts.\n\n\n\n\nJensen, John R et al. 1996. Introductory Digital Image Processing: A Remote Sensing Perspective. Ed. 2. Prentice-Hall Inc.\n\n\nSiregar, VP, NW Prabowo, SB Agus, and T Subarno. 2018. “The Effect of Atmospheric Correction on Object Based Image Classification Using SPOT-7 Imagery: A Case Study in the Harapan and Kelapa Islands.” In IOP Conference Series: Earth and Environmental Science, 176:012028. IOP Publishing."
  },
  {
    "objectID": "week_6.html#summary",
    "href": "week_6.html#summary",
    "title": "Week 6: Classification I",
    "section": "Summary",
    "text": "Summary\nThis week we went through the following topics in the lecture and in the practical:\n\nThe usage of classified data in studies\n\nUrban expansion, air pollution and LULC, urban green spaces, monitoring forests and illegal logging, forest fires\n\nHow to conduct classification of remotely sensed data\n\nClassification and Regression Tree (CART) classifier and issues regarding overfitting\nRandom Forest classifier\nUnsupervised methods\n\nDBSCAN, ISODATA\n\nSupervised methods\n\nMaximum likelihood, Support Vector Machine (SVM)\n\nConsiderations to be given\n\n\nFor the summary I will provide a description of the Random Forest classifier and the CART classifier which Random Forest is built on, which is one of machine learning methods we went through which are commonly used for classification and considered in the practical. In order to understand the RF Classifier, it is crucial to understand how the CART Classifier works.\n\nCART\n\nType of Decision tree which may be used for classification which involves classifying into discrete categories or for regression which involves the prediction of continuous variables\nMay calculate the Gini Impurity for the quantification of the impurity considering the weights (mixture of categories)\n\nRegression tree\n\nCalculation of sum of squares regression (SSR) for different thresholds – begin with the one with lowest SSR, repeat the process\nA good model – balancing bias (high = oversimplification of the model) and variance (high = not generalisable on unseen data) – trade-off relationship\nHow to avoid overfitting\n\nPutting a limit on how trees can go – e.g. setting a threshold for minimum number of observations in each slit to prevent overfitting\nWeakest link pruning (Mangale 2020)\n\nStarts with original full size tree – calculate the SSR at each leaf and add all together four the total SSR for the whole tree\nCalculate the total SSR for each sub tree (remove a leaf one by one) – should get larger with fewer leaves\nCalculation of tree score = SSR + alpha * T\nalpha – tuning parameter\n\nstart with alpha = 0 – full tree will have lowest tree score\nIncrease until removing a leaf will give a lower tree score and repeat until there is only one leaf left\nGo back to the full dataset and conduct train-test split\nUse each of the alpha values for the training data for making a new tree and sub-trees that minimises the tree score\nCalculate the SSR for new each tree with the testing data – which tree has the smallest??\nConduct train and test split again – 10 times cross validation\nChoose alpha value which gives the lowest SSR with testing data\n\nT – tree complexity obesity (number of leaves in tree or subtree)\n\n\n\n\n\n\n\nExamples of Regressions Trees - Source: DataCamp\n\n\n\nRandom Forest Classification (Breiman 2001; Belgiu and Drăguţ 2016)\n\nInvolves many classification decision trees for making a prediction\ncreated by selecting a subset of training samples through replacement (bagging approach); the same sample may be selected multiple times\nApproximately two-thirds of samples used for training (in-bag samples), the remaining one-third used for testing (out-of-the bag samples)\nError estimate: out-of-bag (OOB) error – number of correct predicted/total\nNeed to set two parameters – the number of decision trees & the number of variables for septic on and testing for the best split when growing the trees\nImportant to analyse the sensitivity to the sampling design\nUsage of filter methods for feature selection based on importance\n\n\n\n\n\nTraining and Testing Stages of Random Forest Classifier (Belgiu and Drăguţ 2016, 26)\n\n\n\nComparison of Random Forest to other machine learning methods (Belgiu and Drăguţ 2016; Chutia et al. 2016)\n\nStrengths\n\nImplementation is simple requiring only the adjustment of the two parameters stated above\nNo need to conduct cross validation or acquire a separate test set to retrieve an unbiased estimate of test set error\nReduces overfitting\n\nLimitations\n\nThe performance may be highly influenced by the correlation between any given trees and the strength of each tree in the forest\n\nSuitable for highly dimensional input data such as hyperspectral imagery or multi source data compared to SVM\nWorse performance for object based image analysis compared to SVM\n\n\n\nPractical Output\nRandom Forest Classification of Hirakata, Osaka, Japan\n - Out of Bag Error Estimate: 0.45% - Training overall accuracy: 99.95% - Validation overall accuracy: 99.54%"
  },
  {
    "objectID": "week_6.html#application",
    "href": "week_6.html#application",
    "title": "Week 6: Classification I",
    "section": "Application",
    "text": "Application\nThe case study I will like to consider here as an example of research using random forest classifier of remotely sensed data is the study by Gibson et al. (2020). The article is about fire severity which measure the loss of organic matter due to the fire (Keeley 2009, 118). It is important to understand the spatial patterns of fire severity for fire management and ecological and climate change research related to fires. The objectives of the paper are stated as 1) the assessment of how useful high resolution Sentinel imagery is for mapping fire severity, 2) the evaluation of the classification for fire severity based on traditional spectral indices and fractional cover products, and 3) the identification of landscape factors that are related to misclassification (ibid.)\n\n\n\nLocation of fires studied in NSW, Australia (Gibson et al. 2020)\n\n\nThe region of interest is New South Wales, and the focus is on eight wildfires (between 2017 and 2018, ranging from one day to two weeks) within the area. These sites were selected because there were high spatial resolution (less than 50cm) digital aerial photography with four bands (blue, green, red and NIR) for the post-fire period of them that overlapped with Sentinel 2 satellite imagery. These images went through aerial photograph interpretation for the generation of homogenous sample area polygons and classified based on five severity classes which have been used for the evaluation of the different degrees of post-fire change. Random sampling points are based on these polygons, being randomly distributed and reflecting the real-world situation. For the remotely sensed data, Sentinel 2 satellite imagery with cloud cover less than 5% and with dates near to the period when each of the fires occurred were chosen. Based on the calculation of the proportion of photosynthetic vegetation, non-photosynthetic vegetation, and bare ground cover using a fractional cover model (originally developed for Landsat imagery so need to apply surface reflectance adjustment beforehand) for each pixel, fractional cover products for each image are yielded. In addition, five candidate fire severity indices are calculated for each pre-and post- image pair (The formulas for acquiring these indices may referred to in the paper):\n\ndifferenced normalised burn ratio (dNBR)\nrelativised dNBR (RdNBR)\nrelativised change in total fractional cover (RdFCT)\nchange in bare fractional cover (dFCB)\nthe differenced normalised differenced vegetation index (dNDVI)\nthe differenced Bare Soil Index (dBSI).\n\nFor the Random Forest Classifier, a 70%-30% split was used for the training and testing split.\n\nNumber of trees: 500\nNumber of predictor variables: the square root of the number of variables used in the model\n\nA systematic comparison of models with each of the candidate severity index and their combinations was involved. Training data for unburnt areas were only considered from 2-4 km of the areas affected by the fire. The accuracy of the classification is considered through the balanced accuracy, which is the average of sensitivity and specificity and the Kappa statistic.  \nInteresting findings include\n\nHigh accuracy (mean balanced accuracy of 88%)\n\nHigher classification accuracy for unburnt and higher severity classes, low classification accuracy for lower severity classes (low and moderate)\n\nThe difference in scale between training and resolution of the satellite imagery maybe reflected\nModerate class – lowest representation of points, can increase the volume of training data and use a secondary classification approach\nImportance of interpreting the results with knowledge of local context \n\n\n\n\n\n\nAccuracy results (Gibson et al. 2020)\n\n\nIn the lecture, we were encouraged not to just present a study that classifies the imagery, but also think about how the data may be used. In this case, this classification may be useful for restoring the forests; at the national scale the Australian government has announced the initial investment of $50 million for long-term protection and restoration following the Australian bushfires between 2019 and 2020 (Australia High Commission United Kingdom, n.d.), and this classification may inform which areas require the most immediate intervention."
  },
  {
    "objectID": "week_6.html#reflection",
    "href": "week_6.html#reflection",
    "title": "Week 6: Classification I",
    "section": "Reflection",
    "text": "Reflection\nIn CASA0006, we also learnt about different machine learning methods, being introduced to the same algorithms. However, the application of these methods in Remote Sensing completely new, and it was interesting to see how it overlapped with what we have learnt in CASA0006 and also what is perhaps more specific to remote sensing (I don’t think we covered weakest link pruning in CASA0006). I have decided to specifically focus on CART and Random Forest Classification for this learning diary, but if time permitted, I would have liked to explore the other methods in more detail as well, in terms of its content, application, and how it can be conducted in Google Earth Engine. I wonder how the results of the paper I introduced in the application section may differ if they tried using a different classification method. I\n\n\n\n\nAustralia High Commission United Kingdom. n.d. “Bushfire Relief and Recovery.” https://uk.embassy.gov.au/lhlh/bushfirerecovery.html.\n\n\nBelgiu, Mariana, and Lucian Drăguţ. 2016. “Random Forest in Remote Sensing: A Review of Applications and Future Directions.” ISPRS Journal of Photogrammetry and Remote Sensing 114: 24–31.\n\n\nBreiman, Leo. 2001. “Random Forests.” Machine Learning 45: 5–32.\n\n\nChutia, Dibyajyoti, DK Bhattacharyya, Kandarpa Kumar Sarma, Ranjan Kalita, and Singuluri Sudhakar. 2016. “Hyperspectral Remote Sensing Classifications: A Perspective Survey.” Transactions in GIS 20 (4): 463–90.\n\n\nGibson, Rebecca, Tim Danaher, Warwick Hehir, and Luke Collins. 2020. “A Remote Sensing Approach to Mapping Fire Severity in South-Eastern Australia Using Sentinel 2 and Random Forest.” Remote Sensing of Environment 240: 111702. https://doi.org/https://doi.org/10.1016/j.rse.2020.111702.\n\n\nKeeley, J. E. 2009. “Fire Intensity, Fire Severity and Burn Severity: A Brief Review and Suggested Usage.” International Journal of Wildland Fire 18 (1): 116–26. https://doi.org/10.1071/WF07049.\n\n\nMangale, Sanchita. 2020. “Decision Tree-Pruning-Cost Complexity Method.” https://sanchitamangale12.medium.com/decision-tree-pruning-cost-complexity-method-194666a5dd2f#:~:text=Weakest%20link%20pruning%20works%20by,in%20the%20number%20of%20leaves."
  },
  {
    "objectID": "week_6.html#section",
    "href": "week_6.html#section",
    "title": "4  Week 8",
    "section": "4.4 ",
    "text": "4.4"
  },
  {
    "objectID": "week_8.html#summary",
    "href": "week_8.html#summary",
    "title": "Week 8: Temperature",
    "section": "Summary",
    "text": "Summary\nThis week we went through mainly two topics in the lecture and the practical:\n\nTemperature and Policy\n\nWhat is the urban heat island\nThe cost of the urban heat island\nGlobal and local policies addressing this issue\n\nExtraction of Temperature from Satellite Data\n\nHow can remotely sensed data may be used\nMetropolitan UHI reduction activities\nRethinking planning requirements – case study\n\n\nTo start off, I will provide a summary of the content through a Q&A format of questions to be considered for the topic of Urban Heat Island, which we covered in the lecture and is an “an important environmental problem facing all large urban centers” (Hulley 2012, 95). Some references to Phoenix will be made here as it is the choice of city for the group presentation. .\nWhat is the Urban Heat Island?\n\nThe Urban Heat Island refers to the phenomena where an urban or metropolitan area has a significantly higher temperature compared to the surrounding rural areas due to human activities (Takebayashi and Moriyama 2020)\n\n\n\n\nVisualisation of Urban Heat Island - Source: ESA\n\n\nHow does it occur?\n\nThe following diagram demonstrates how the Urban Heat Island is caused, showing how there are many factors involved in the process of the generation of this effect. The main two sources of Urban Heat Island can be attributed to the heat generated from urban structures from their consumption and re-radiation of solar radiation (“Urban design and structure related” in the diagram) and anthropogenic heat from sources such as power plants, automobiles, air-conditioners (Rizwan, Dennis, and Chunho 2008, 121).\n\n\n\n\nThe Generation of Urban Heat Island (Rizwan, Dennis, and Chunho 2008, 121)\n\n\nWhat are the (expected) impacts of Urban Heat Island? (Considering Phoenix)\n\nSocial\n\nTotal of 323 heat-related deaths in 2020, reaching a recorded high for consecutive five years (The Nature Conservatory and AECOM 2021)\n\nEnvironmental\n\n1°F increase in daily low temperatures associated with 290 gallons increase an average monthly usage of water for a typical single-family unit (Guhathakurta and Gober 2007)\n\nEconomic\n\nInaction towards the mitigation of heat resulting in loss of $1.9 billion (medium stabilization scenario) and $2.3 billion (high emission scenario) annually (The Nature Conservatory and AECOM 2021)\n\n\nWhat are there any policies addressing this issue?\n\nGlobal policies\n\nNew Urban Agenda. Sustainable Development Goals\n\nWide frame goals regarding sustainability of cities, not specific to heat\n\nBeating the Heat Handbook\nUseful as a guidance stating the importance of integrating heat mitigation strategies into policy – first major document\nDoes not consider specifics (how to use data, what planing rules need to be changed, what roles are required, interest in government etc)\n\nLocal policies - case of Phoenix\n\nPhoenix climate action plan – 2050 heat section goal (Phoenix 2021)\n\nIncrease in green infrastructure and tree canopy\nIncrease in open spaces and green spaces\nImplementation of Cool Pavement and Cool Corridors Programs\n\nShould develop a better understanding of the specific locations for the implementation of green space and cooling?\n\n\n\n\n\nSelection of Practical Outputs\nArea of Interest: Arizona, U.S.A (state that Phoenix is capital of)\n\n\n\nLANDSAT Temperature Image\n\n\n\n\n\nMODIS Temperature Image\n\n\n\n\n\nTime Series Analysis of MODIS Data"
  },
  {
    "objectID": "week_8.html#application",
    "href": "week_8.html#application",
    "title": "Week 8: Temperature",
    "section": "Application",
    "text": "Application\nRemote sensing may be used to address the issue from both the problem side in terms of how the urban heat island effect intensifies with land cover change and the solution side in terms of the possible interventions and its effectiveness. Here I will introduce two studies, both based in Phoenix, Arizona, which each consider the urban heat island problem with the two perspectives respectively.\nThe study by Wang et al. (2016) studies how the urban heat island effect has expanded spatially across time and its relationship with land usage land cover (LULC) in the Phoenix Metropolitan Area. For the temperature data, it uses land surface temperature data from MODIS, specifically 8-day composite June imagery due to ideal weather conditions. One limitation of the usage of MODIS is the low spatial resolution (1000m). However, it is argued that the generation for a relatively large sample size may account for this limitation. A total of 58 images are collected. For the classified LULC map, Landsat Data for 2000 (Landsat 5 Thematic Mapper Image) and 2014 (Landsat 8 Operational Land Imager) are used, based on 30m spatial resolution. The data is classified into a total of 6 classes (water, impervious surface, vegetation, urban/residential area, open soil and fallow cropland) using the Iterative Self-Organising Data Analysis (ISODATA) unsupervised classification algorithm. The accuracy assessment is based on a minimum of 50 sample points for each class produced from a stratified random sampling approach and is conducted using Google Earth and local observations.\n\n\n\nMethodology Workflow (Wang et al. 2016)\n\n\nThe study demonstrates that the areas which went through the most change in land surface temperature for both daytime and nighttime are mainly around the outer boundary of Phoenix Metropolitan Area, demonstrating patterns of urban sprawl. In addition, change from various LULC classes to urban, residential and imperious surfaces as the main factors for the urban heat island in the area. Furthermore, vegetation cover is associated with decrease in land surface temperature.\nThe study conducted by Zhang et al. (2017) propose a framework for the identification of the optimal location and configuration of new green spaces based on the integration of GIS, remote sensing, spatial statistics and spatial optimisation, and is applied to Phoenix. Arizona. The remote sensing data used here is from ASTER, specifically the ASTER_08 product, which is generated from the five thermal infrared bands, containing the surface temperature at 90m spatial resolution. A consecutive day-night imagery (17 June 2010 22:00 and 18 June 2010 11:00) is considered, with the study area consisting of 11466 pixels. Additionally, a land cover classification based on the aerial imagery (four bands – RGB and NIR, 1m spatial resolution) from the National Agricultural Imagery Program. The overall methodological framework is provided in the diagram below.\n\n\n\nFramework (Zhang, Murray, and Turner Ii 2017, 166)\n\n\n\n\n\nGreen Space Allocation Pattern with the Expected Temperature Drop (Zhang, Murray, and Turner Ii 2017, 169)\n\n\nWith this framework, land surface temperature may be expected by 1-2a the local scale, and 0.5 at the regional scale. The locational placement of green spaces is influential, as depending on whether the green space is clustered or dispersed determines at what spatial scale we may observe the cooling effect. This framework may be one possible solution to the question I had regarding Phoenix’s policies for the implementation of green space."
  },
  {
    "objectID": "week_8.html#reflection",
    "href": "week_8.html#reflection",
    "title": "Week 8: Temperature",
    "section": "Reflection",
    "text": "Reflection\nUrban Heat Island is a very familiar topic growing up in the concrete jungles of Tokyo, spending very hot summers with high humidity every year. Therefore, I was able to connect my experiences in the past to the impacts of the urban heat island. It also made me consider whether the policies at both the global scale and more local scale are actually effective in mitigating the heat, and whether these policies are actually taking into consideration remote sensing data in any sort of way. Researching possible articles and policies to consider for the application section, it came to my attention that many of the studies were primarily focused on how the urban island affect arises or expands and how the results may be used for effective policy in a rather passive manner but not many cities have not taken them into consideration. Perhaps there is a limitation in that there are not many people familiar with both policy and remote sensing, but I think it would be beneficial if we can see more remote sensing data being applied for this problem.\n\n\n\n\nGuhathakurta, Subhrajit, and Patricia Gober. 2007. “The Impact of the Phoenix Urban Heat Island on Residential Water Use.” Journal of the American Planning Association 73 (3): 317329.\n\n\nHulley, M. E. 2012. “5 - The Urban Heat Island Effect: Causes and Potential Solutions.” In Metropolitan Sustainability, edited by Frank Zeman, 79–98. Woodhead Publishing Series in Energy. Woodhead Publishing. https://doi.org/https://doi.org/10.1533/9780857096463.1.79.\n\n\nPhoenix. 2021. “Climate Action Plan.” https://www.phoenix.gov/oepsite/Documents/2021ClimateActionPlanEnglish.pdf.\n\n\nRizwan, Ahmed Memon, Leung YC Dennis, and LIU Chunho. 2008. “A Review on the Generation, Determination and Mitigation of Urban Heat Island.” Journal of Environmental Sciences 20 (1): 120–28.\n\n\nTakebayashi, Hideki, and Masakazu Moriyama. 2020. “Chapter 1 - Background and Purpose.” In Adaptation Measures for Urban Heat Islands, edited by Hideki Takebayashi and Masakazu Moriyama, 1–8. Academic Press. https://doi.org/10.1016/B978-0-12-817624-5.00001-4.\n\n\nThe Nature Conservatory, and AECOM. 2021. “Economic Assessment of Heat in the Phoenix Metro Area.” https://www.nature.org/content/dam/tnc/nature/en/documents/TNC_EcoHeatAssement_AZ_Report.pdf.\n\n\nWang, Chuyuan, Soe W Myint, Zhihua Wang, and Jiyun Song. 2016. “Spatio-Temporal Modeling of the Urban Heat Island in the Phoenix Metropolitan Area: Land Use Change Implications.” Remote Sensing 8 (3): 185.\n\n\nZhang, Yujia, Alan T Murray, and BL Turner Ii. 2017. “Optimizing Green Space Locations to Reduce Daytime and Nighttime Urban Heat Island Effects in Phoenix, Arizona.” Landscape and Urban Planning 165: 162–71."
  },
  {
    "objectID": "week_4.html#references",
    "href": "week_4.html#references",
    "title": "Week 4",
    "section": "References",
    "text": "References\n\n\nBureau of Urban Development Tokyo Metropolitan Government. 2021.\n“Efforts for Pre-Recovery of the City in Preparation for an\nEarthquake Directly Hitting the Tokyo Metropolitan Area\n(首都直下地震等に備えた都市の事前復興の取組).” Bureau of\nUrban Development Tokyo Metropolitan Government. https://www.toshiseibi.metro.tokyo.lg.jp/bunyabetsu/bosai/shuto.html.\n\n\nContreras, Diana, Thomas Blaschke, Stefan Kienberger, and Peter Zeil.\n2013. “Spatial Connectivity as a Recovery Process Indicator:\nThe L’Aquila Earthquake.”\nTechnological Forecasting and Social Change 80 (9): 1782–1803.\n\n\nGhaffarian, Saman, Norman Kerle, and Tatiana Filatova. 2018.\n“Remote Sensing-Based Proxies for Urban Disaster Risk Management\nand Resilience: A Review.” Remote Sensing\n10 (11): 1760.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David\nThau, and Rebecca Moore. 2017. “Google Earth\nEngine: Planetary-Scale Geospatial Analysis\nfor Everyone.” Remote Sensing of Environment 202: 18–27.\n\n\nKucharczyk, Maja, and Chris H Hugenholtz. 2021. “Remote Sensing of\nNatural Hazard-Related Disasters with Small Drones: Global\nTrends, Biases, and Research Opportunities.” Remote Sensing\nof Environment 264: 112577.\n\n\nLiu, Cheng-Chien, Ming-Chang Shieh, Ming-Syun Ke, and Kung-Hwa Wang.\n2018. “Flood Prevention and Emergency Response System Powered by\nGoogle Earth Engine.”\nRemote Sensing 10 (8): 1283.\n\n\nPlatt, Stephen, Daniel Brown, and Martin Hughes. 2016. “Measuring\nResilience and Recovery.” International Journal of Disaster\nRisk Reduction 19: 447–60.\n\n\nSchwarz, Michael. 2014. “Risky Cities: Tokyo.”\nZurich: Swiss Re. https://www.swissre.com/dam/jcr:22462410-f30f-46a3-9bc0-4713c5760928/Factsheet_Tokyo-Yokohama_WEB.pdf.\n\n\nThe City of Yokohama. 2013. “Yokohama City\nEarthquake Disaster Prevention\nStrategy (横浜市地震防災戦略).” The City of\nYokohama. https://www.city.yokohama.lg.jp/kurashi/bousai-kyukyu-bohan/bousai-saigai/bosaikeikaku/keikaku/keikakutou/shinsai.files/jisinbousaisenryaku.pdf.\n\n\n———. 2019. “Estimated Damage in Yokohama\nCity (横浜市の被害想定).” The City of\nYokohama. https://www.city.yokohama.lg.jp/kurashi/bousai-kyukyu-bohan/bousai-saigai/wagaya/jishin/higai/higaisoutei.html.\n\n\nThe City of Yokohama Europe Representative Office. n.d. “The\nReasons Why Yokohama Is Chosen\n(横浜が選ばれる理由).” The City of Yokohama Europe\nRepresentative Office. Accessed February 14, 2023. https://yokohama-city.de/jp/business-opportunities/.\n\n\nUnited Nations Office for Disaster Risk Reduction. n.d. “What Is\nthe Sendai Framework for Disaster\nRisk Reduction?” United Nations\nOffice Fot Disaster Risk Reduction. Accessed February 15, 2023. https://www.undrr.org/implementing-sendai-framework/what-sendai-framework.\n\n\nYokohama City Disaster Prevention Council. 2021. “Yokohama\nCity Disaster Prevention\nPlan Earthquake Countermeasures 2021\n(横浜市防災計画震災対策編).” City of Yokohama. https://www.city.yokohama.lg.jp/kurashi/bousai-kyukyu-bohan/bousai-saigai/bosaikeikaku/keikaku/keikakutou/shinsai.files/shinsaitaisaku-all.pdf."
  },
  {
    "objectID": "week_5.html",
    "href": "week_5.html",
    "title": "Week 5",
    "section": "",
    "text": "This week we went through the following content in the lecture:\n\nThe set up of Google Earth Engine (GEE)\n\nTerms specific to GEE\nRelating spatial data formats to GEE\nExplanation of the client and server side\nScale (resolution)\nProjections\n\n\nIn the practical, we saw the different types of data that could be used in Google Earth Engine, and what kinds of preparation, processing, and analysis could be conducted.\nAs a summary, here I provide a mind-map of the article by Gorelick et al. (2017). According to Google Scholar, this article has been cited in 6963 pieces of academic work, which I think demonstrates the strong influence of GEE in the field of Remote Sensing in terms of the changing the workflow.\nFor the application of GEE, I will introduce the review article by Liu et al. (2018), which introduces the Flood Prevention and Emergency and Response System (FPERS) in Taiwan. It is a paper that presents how the usage of Google Earth Engine may be beneficial for policies. The attached figure is a flow chart of how the FPERS supports decision making in the pre-flood, during-flood and post-flood stage.\nThe merits of using GEE for this FPERS maybe outlined as below (Liu et al. 2018):\n\nThe ability to prepare and update images for analysis for analysis and visualisation\n\nCost effective for accessing up to date data (Sentinel-2 data for every five days)\n\nIncorporation of the global topological data, allowing for 3D display of the data\n\nHowever, it is quite important that they also consider the limitations in GEE for the usage of this system. Liu et al. (2018) state that the GEE lacks the flexibility for managing and searching an expansive database with its increasing number of data, requiring the knowledge of the data the user wants to use and selecting the data based on conditions. Moreover, due to the depreciation of Google Earth API, the services were downgraded to Google Maps API, only allowing for 2D Display. This highlights the challenges which may arise when relying on a single commercial platform.\nThe have the amount of attention given to Google Earth Engine and its applications in different areas has been interesting. In terms of the technicality, I think the computational easiness which has been addressed throughout the lecture and in the works of Gorelick of Google Earth Engine is a great advantage, after using RStudio for some of the analysis in previous weeks. The range of things that is made possible with GEE in FPERS is quite astonishing. However, obviously GEE is not perfect for every single application, so I think it is important to develop an understanding what can be done well and what cannot. Moreover, in terms of accessibility, the paper on FPERS by Liu et al. was informing about the limitations of GEE and how it is not perhaps being accessible for everyone as I thought and how it promotes it is. The point regarding the reliance on a single platform was quite interesting, and I would like to perhaps explore alternative platforms for analysis in the future.\n\n\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. 2017. “Google Earth Engine: Planetary-Scale Geospatial Analysis for Everyone.” Remote Sensing of Environment 202: 18–27.\n\n\nLiu, Cheng-Chien, Ming-Chang Shieh, Ming-Syun Ke, and Kung-Hwa Wang. 2018. “Flood Prevention and Emergency Response System Powered by Google Earth Engine.” Remote Sensing 10 (8): 1283."
  },
  {
    "objectID": "week_8.html#this-week-in-the-lecture-we-went-through-two-mainly-two-topics",
    "href": "week_8.html#this-week-in-the-lecture-we-went-through-two-mainly-two-topics",
    "title": "7  Week 8",
    "section": "7.1 This week in the lecture, we went through two mainly two topics:",
    "text": "7.1 This week in the lecture, we went through two mainly two topics:\n-       Temperature and Policy\n-       Extraction of Temperature from Satellite Data\nIn the practical, in terms of the Google Earth Engine, we went through how data from Landsat and MODIS may be used for the extraction of temperature.\nTo start off, I will provide a summary of the content through a Q&A format of questions to be considered for the topic of Urban Heat Island, which we covered in the lecture and is an \"an important environmental problem facing all large urban centers\".\nWhat is the Urban Heat Island?\n-       The Urban Heat Island refers to the phenomena where an urban or metropolitan area has a significantly higher temperature compared to the surrounding rural areas due to human activities ()\nHow does it occur?\n-       The following diagram demonstrates how the Urban Heat Island is caused, showing how there are many factors involved in the process of the generation of this effect. The main two sources of Urban Heat Island can be attributed to the heat generated from urban structures from their consumption and re-radiation of solar radiation (\"Urban design and structure related\" in the diagram) and anthropogenic heat from sources such as power plants, automobiles, air-conditioners [].\nWhat are the impacts of Urban Heat Island?\n-       Urban heat island can affect the environment and quality of life an area in different ways\nØ  Increase in energy consumption – overall electricity demand and peak energy demand\nØ  Increase in emissions of air pollutants and greenhouse gas\nØ  Heat-related deaths and illnesses especially among vulnerable groups of people ()\nWhat are there any policies addressing this issue?\nRemote sensing may be used to address the issue from both the problem side in terms of how the urban heat island effect intensifies with land cover change and the solution side in terms of the effectiveness of the possible policy interventions. Here I will introduce two studies, both based in Phoenix, Arizona, which each consider the urban heat island problem with the two perspectives respectively.\nThe study by Wang et al studies how the urban heat island effect has expanded spatially across time and its relationship with land usage and land cover (LULC) in the Phoenix Metropolitan Area. For the temperature data, it uses land surface temperature data from MODIS, specifically 8-day composite June imagery due to ideal weather conditions. One limitation of the usage of MODIS is the low spatial resolution (1000m). However, it is argued that the generation for a relatively large sample size may account for this limitation. A total of 58 images are collected. For the classified LULC map, Landsat Data for 2000 (Landsat 5 Thematic Mapper Image) and 2014 (Landsat 8 Operational Land Imager) are used, based on 30m spatial resolution. The data is classified into a total of 6 classes (water, impervious surface, vegetation, urban/residential area, open soil and fallow cropland) using the Iterative Self-Organising Data Analysis unsupervised classification algorithm. The accuracy assessment is based on a minimum of 50 sample points for each class produced from a stratified random sampling approach, and is conducted using Google Earth and local observations.\nThe study conducted by\nReflection\nIt is interesting to learn how the"
  },
  {
    "objectID": "week_5.html#references",
    "href": "week_5.html#references",
    "title": "Week 5",
    "section": "References",
    "text": "References\n\n\nBureau of Urban Development Tokyo Metropolitan Government. 2021.\n“Efforts for Pre-Recovery of the City in Preparation for an\nEarthquake Directly Hitting the Tokyo Metropolitan Area\n(首都直下地震等に備えた都市の事前復興の取組).” Bureau of\nUrban Development Tokyo Metropolitan Government. https://www.toshiseibi.metro.tokyo.lg.jp/bunyabetsu/bosai/shuto.html.\n\n\nContreras, Diana, Thomas Blaschke, Stefan Kienberger, and Peter Zeil.\n2013. “Spatial Connectivity as a Recovery Process Indicator:\nThe L’Aquila Earthquake.”\nTechnological Forecasting and Social Change 80 (9): 1782–1803.\n\n\nGhaffarian, Saman, Norman Kerle, and Tatiana Filatova. 2018.\n“Remote Sensing-Based Proxies for Urban Disaster Risk Management\nand Resilience: A Review.” Remote Sensing\n10 (11): 1760.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David\nThau, and Rebecca Moore. 2017. “Google Earth\nEngine: Planetary-Scale Geospatial Analysis\nfor Everyone.” Remote Sensing of Environment 202: 18–27.\n\n\nKucharczyk, Maja, and Chris H Hugenholtz. 2021. “Remote Sensing of\nNatural Hazard-Related Disasters with Small Drones: Global\nTrends, Biases, and Research Opportunities.” Remote Sensing\nof Environment 264: 112577.\n\n\nLiu, Cheng-Chien, Ming-Chang Shieh, Ming-Syun Ke, and Kung-Hwa Wang.\n2018. “Flood Prevention and Emergency Response System Powered by\nGoogle Earth Engine.”\nRemote Sensing 10 (8): 1283.\n\n\nPlatt, Stephen, Daniel Brown, and Martin Hughes. 2016. “Measuring\nResilience and Recovery.” International Journal of Disaster\nRisk Reduction 19: 447–60.\n\n\nSchwarz, Michael. 2014. “Risky Cities: Tokyo.”\nZurich: Swiss Re. https://www.swissre.com/dam/jcr:22462410-f30f-46a3-9bc0-4713c5760928/Factsheet_Tokyo-Yokohama_WEB.pdf.\n\n\nThe City of Yokohama. 2013. “Yokohama City\nEarthquake Disaster Prevention\nStrategy (横浜市地震防災戦略).” The City of\nYokohama. https://www.city.yokohama.lg.jp/kurashi/bousai-kyukyu-bohan/bousai-saigai/bosaikeikaku/keikaku/keikakutou/shinsai.files/jisinbousaisenryaku.pdf.\n\n\n———. 2019. “Estimated Damage in Yokohama\nCity (横浜市の被害想定).” The City of\nYokohama. https://www.city.yokohama.lg.jp/kurashi/bousai-kyukyu-bohan/bousai-saigai/wagaya/jishin/higai/higaisoutei.html.\n\n\nThe City of Yokohama Europe Representative Office. n.d. “The\nReasons Why Yokohama Is Chosen\n(横浜が選ばれる理由).” The City of Yokohama Europe\nRepresentative Office. Accessed February 14, 2023. https://yokohama-city.de/jp/business-opportunities/.\n\n\nUnited Nations Office for Disaster Risk Reduction. n.d. “What Is\nthe Sendai Framework for Disaster\nRisk Reduction?” United Nations\nOffice Fot Disaster Risk Reduction. Accessed February 15, 2023. https://www.undrr.org/implementing-sendai-framework/what-sendai-framework.\n\n\nYokohama City Disaster Prevention Council. 2021. “Yokohama\nCity Disaster Prevention\nPlan Earthquake Countermeasures 2021\n(横浜市防災計画震災対策編).” City of Yokohama. https://www.city.yokohama.lg.jp/kurashi/bousai-kyukyu-bohan/bousai-saigai/bosaikeikaku/keikaku/keikakutou/shinsai.files/shinsaitaisaku-all.pdf."
  },
  {
    "objectID": "week_5.html#summary",
    "href": "week_5.html#summary",
    "title": "Week 5: Google Earth Engine I",
    "section": "Summary",
    "text": "Summary\nThis week we went through the following content in the lecture:\n\nThe set up of Google Earth Engine (GEE)\n\nTerms specific to GEE\nRelating spatial data formats to GEE\nExplanation of the client and server side\nScale (resolution)\nProjections\n\n\nIn the practical, we saw the different types of data that could be used in Google Earth Engine, and what kinds of preparation, processing, and analysis could be conducted.\nAs a summary, here I provide a mind-map of the article by Gorelick et al. (2017). According to Google Scholar, this article has been cited in 6963 pieces of academic work, which I think demonstrates the strong influence of GEE in the field of Remote Sensing in terms of the changing the workflow.\n\n\n\nMind Map - Google Earth Engine"
  },
  {
    "objectID": "week_5.html#application",
    "href": "week_5.html#application",
    "title": "Week 5: Google Earth Engine I",
    "section": "Application",
    "text": "Application\nFor the application of GEE, I will introduce the review article by Liu et al. (2018), which introduces the Flood Prevention and Emergency and Response System (FPERS) in Taiwan. It is a paper that presents how the usage of Google Earth Engine may be beneficial for policies. The attached figure is a flow chart of how the FPERS supports decision making in the pre-flood, during-flood and post-flood stage.\n\n\n\nFlowchart - FPERS\n\n\nThe merits of using GEE for this FPERS maybe outlined as below (Liu et al. 2018):\n\nThe ability to prepare and update images for analysis for analysis and visualisation\n\nCost effective for accessing up to date data (Sentinel-2 data for every five days)\n\nIncorporation of the global topological data, allowing for 3D display of the data\n\nHowever, it is quite important that they also consider the limitations in GEE for the usage of this system. Liu et al. (2018) state that the GEE lacks the flexibility for managing and searching an expansive database with its increasing number of data, requiring the knowledge of the data the user wants to use and selecting the data based on conditions. Moreover, due to the depreciation of Google Earth API, the services were downgraded to Google Maps API, only allowing for 2D Display. This highlights the challenges which may arise when relying on a single commercial platform."
  },
  {
    "objectID": "week_5.html#summary-1",
    "href": "week_5.html#summary-1",
    "title": "Week 5: Google Earth Engine I",
    "section": "Summary",
    "text": "Summary\nThe amount of attention given to Google Earth Engine and its applications in different areas has been interesting. In terms of the technicality, I think the computational easiness which has been addressed throughout the lecture and in the works of Gorelick et al. (2017) of Google Earth Engine is a great advantage, after using RStudio for some of the analysis in previous weeks. The range of things that is made possible with GEE in FPERS is quite astonishing. However, obviously GEE is not perfect for every single application, so I think it is important to develop an understanding what can be done well and what cannot. Moreover, in terms of accessibility, the paper on FPERS by Liu et al. (2018) was informing about the limitations of GEE and how it is not perhaps being accessible for everyone as I thought and how it promotes it is. The point regarding the reliance on a single platform was quite interesting, and I would like to perhaps explore alternative platforms for analysis in the future.\n\n\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. 2017. “Google Earth Engine: Planetary-Scale Geospatial Analysis for Everyone.” Remote Sensing of Environment 202: 18–27.\n\n\nLiu, Cheng-Chien, Ming-Chang Shieh, Ming-Syun Ke, and Kung-Hwa Wang. 2018. “Flood Prevention and Emergency Response System Powered by Google Earth Engine.” Remote Sensing 10 (8): 1283."
  },
  {
    "objectID": "week_3.html#this-week-we-went-through-the-following-content-in-the-lecture-and-the-practical",
    "href": "week_3.html#this-week-we-went-through-the-following-content-in-the-lecture-and-the-practical",
    "title": "3  Week 3",
    "section": "3.1 This week we went through the following content in the lecture and the practical:",
    "text": "3.1 This week we went through the following content in the lecture and the practical:\n\nCorrections – the pre-processing of the raw remotely sensed data\n\nGeometric\nAtmospheric\nOrthorectification / Topographic\nRadiometric\n\nData joining and enhancement\n\nFeathering\nImage enhancement\n\n\nHere I will focus on atmospheric correction – it seems that this type of correction is the most common, as most of the results I saw with the Google search of \"remote sensing corrections\" seemed to deal with atmospheric correction.\nBelow is a mind map of atmospheric correction, based on the lecture materials and the work by Jensen (1996). It puts together the importance of applying the atmospheric correction, and the different methods which can be employed based on the condition of the image and the capability.\n\n3.1.1 Practical Content\nSome of the equations used in Atmospheric Correction\nAbsolute Correction –\nCode for performing DOS correction"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Australia High Commission United Kingdom. n.d. “Bushfire Relief\nand Recovery.” https://uk.embassy.gov.au/lhlh/bushfirerecovery.html.\n\n\nBelgiu, Mariana, and Lucian Drăguţ. 2016. “Random Forest in Remote\nSensing: A Review of Applications and Future\nDirections.” ISPRS Journal of Photogrammetry and Remote\nSensing 114: 24–31.\n\n\nBreiman, Leo. 2001. “Random Forests.” Machine\nLearning 45: 5–32.\n\n\nBrenning, Alexander, Donovan Bangs, and Mark Becker. 2018.\n“RSAGA: SAGA Geoprocessing\nand Terrain Analysis.” https://cran.r-project.org/web/packages/RSAGA/index.html.\n\n\nBureau of Urban Development Tokyo Metropolitan Government. 2021.\n“Efforts for Pre-Recovery of the City in Preparation for an\nEarthquake Directly Hitting the Tokyo Metropolitan Area\n(首都直下地震等に備えた都市の事前復興の取組).” Bureau of\nUrban Development Tokyo Metropolitan Government. https://www.toshiseibi.metro.tokyo.lg.jp/bunyabetsu/bosai/shuto.html.\n\n\nChutia, Dibyajyoti, DK Bhattacharyya, Kandarpa Kumar Sarma, Ranjan\nKalita, and Singuluri Sudhakar. 2016. “Hyperspectral Remote\nSensing Classifications: A Perspective Survey.” Transactions\nin GIS 20 (4): 463–90.\n\n\nContreras, Diana, Thomas Blaschke, Stefan Kienberger, and Peter Zeil.\n2013. “Spatial Connectivity as a Recovery Process Indicator:\nThe L’Aquila Earthquake.”\nTechnological Forecasting and Social Change 80 (9): 1782–1803.\n\n\nGareth, James, Witten Daniela, Hastie Trevor, and Tibshirani Robert.\n2013. An Introduction to Statistical Learning: With Applications in\nR. Spinger.\n\n\nGhaffarian, Saman, Norman Kerle, and Tatiana Filatova. 2018.\n“Remote Sensing-Based Proxies for Urban Disaster Risk Management\nand Resilience: A Review.” Remote Sensing\n10 (11): 1760.\n\n\nGibson, Rebecca, Tim Danaher, Warwick Hehir, and Luke Collins. 2020.\n“A Remote Sensing Approach to Mapping Fire Severity in\nSouth-Eastern Australia Using Sentinel 2 and Random Forest.”\nRemote Sensing of Environment 240: 111702. https://doi.org/https://doi.org/10.1016/j.rse.2020.111702.\n\n\nGorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David\nThau, and Rebecca Moore. 2017. “Google Earth\nEngine: Planetary-Scale Geospatial Analysis\nfor Everyone.” Remote Sensing of Environment 202: 18–27.\n\n\nGuhathakurta, Subhrajit, and Patricia Gober. 2007. “The Impact of\nthe Phoenix Urban Heat Island on Residential Water Use.”\nJournal of the American Planning Association 73 (3): 317329.\n\n\nHulley, M. E. 2012. “5 - The Urban Heat Island\nEffect: Causes and Potential Solutions.” In Metropolitan\nSustainability, edited by Frank Zeman, 79–98. Woodhead\nPublishing Series in Energy.\nWoodhead Publishing. https://doi.org/https://doi.org/10.1533/9780857096463.1.79.\n\n\nJensen, John R et al. 1996. Introductory Digital Image Processing: A\nRemote Sensing Perspective. Ed. 2. Prentice-Hall Inc.\n\n\nKarasiak, Nicolas, J-F Dejoux, Claude Monteil, and David Sheeren. 2022.\n“Spatial Dependence Between Training and Test Sets: Another\nPitfall of Classification Accuracy Assessment in Remote Sensing.”\nMachine Learning 111 (7): 2715–40.\n\n\nKeeley, J. E. 2009. “Fire Intensity, Fire Severity and Burn\nSeverity: A Brief Review and Suggested Usage.” International\nJournal of Wildland Fire 18 (1): 116–26. https://doi.org/10.1071/WF07049.\n\n\nKucharczyk, Maja, and Chris H Hugenholtz. 2021. “Remote Sensing of\nNatural Hazard-Related Disasters with Small Drones: Global\nTrends, Biases, and Research Opportunities.” Remote Sensing\nof Environment 264: 112577.\n\n\nLiu, Cheng-Chien, Ming-Chang Shieh, Ming-Syun Ke, and Kung-Hwa Wang.\n2018. “Flood Prevention and Emergency Response System Powered by\nGoogle Earth Engine.”\nRemote Sensing 10 (8): 1283.\n\n\nLovelace, Robin, Jacub Nowosad, and Jannes Muenchaw. 2023.\n“Statistical Learning.” Geocomputation\nwith R. https://r.geocompx.org/spatial-cv.html.\n\n\nMangale, Sanchita. 2020. “Decision Tree-Pruning-Cost Complexity\nMethod.” https://sanchitamangale12.medium.com/decision-tree-pruning-cost-complexity-method-194666a5dd2f#:~:text=Weakest%20link%20pruning%20works%20by,in%20the%20number%20of%20leaves.\n\n\nPhoenix. 2021. “Climate Action Plan.” https://www.phoenix.gov/oepsite/Documents/2021ClimateActionPlanEnglish.pdf.\n\n\nPlatt, Stephen, Daniel Brown, and Martin Hughes. 2016. “Measuring\nResilience and Recovery.” International Journal of Disaster\nRisk Reduction 19: 447–60.\n\n\nPloton, Pierre, Frédéric Mortier, Maxime Réjou-Méchain, Nicolas Barbier,\nNicolas Picard, Vivien Rossi, Carsten Dormann, et al. 2020.\n“Spatial Validation Reveals Poor Predictive Performance of\nLarge-Scale Ecological Mapping Models.” Nature\nCommunications 11 (1): 4540.\n\n\nRizwan, Ahmed Memon, Leung YC Dennis, and LIU Chunho. 2008. “A\nReview on the Generation, Determination and Mitigation of\nUrban Heat Island.”\nJournal of Environmental Sciences 20 (1): 120–28.\n\n\nSchratz, Patrick, Jannes Muenchow, Eugenia Iturritxa, Jakob Richter, and\nAlexander Brenning. 2019. “Hyperparameter Tuning and Performance\nAssessment of Statistical and Machine-Learning Algorithms Using Spatial\nData.” Ecological Modelling 406 (August): 109–20. https://doi.org/10.1016/j.ecolmodel.2019.06.002.\n\n\nSchwarz, Michael. 2014. “Risky Cities: Tokyo.”\nZurich: Swiss Re. https://www.swissre.com/dam/jcr:22462410-f30f-46a3-9bc0-4713c5760928/Factsheet_Tokyo-Yokohama_WEB.pdf.\n\n\nSiregar, VP, NW Prabowo, SB Agus, and T Subarno. 2018. “The Effect\nof Atmospheric Correction on Object Based Image Classification Using\nSPOT-7 Imagery: A Case Study in the Harapan\nand Kelapa Islands.” In\nIOP Conference Series:\nEarth and Environmental\nScience, 176:012028. IOP Publishing.\n\n\nTakebayashi, Hideki, and Masakazu Moriyama. 2020. “Chapter 1 -\nBackground and Purpose.” In Adaptation\nMeasures for Urban Heat\nIslands, edited by Hideki Takebayashi and Masakazu\nMoriyama, 1–8. Academic Press. https://doi.org/10.1016/B978-0-12-817624-5.00001-4.\n\n\nThe City of Yokohama. 2013. “Yokohama City\nEarthquake Disaster Prevention\nStrategy (横浜市地震防災戦略).” The City of\nYokohama. https://www.city.yokohama.lg.jp/kurashi/bousai-kyukyu-bohan/bousai-saigai/bosaikeikaku/keikaku/keikakutou/shinsai.files/jisinbousaisenryaku.pdf.\n\n\n———. 2019. “Estimated Damage in Yokohama\nCity (横浜市の被害想定).” The City of\nYokohama. https://www.city.yokohama.lg.jp/kurashi/bousai-kyukyu-bohan/bousai-saigai/wagaya/jishin/higai/higaisoutei.html.\n\n\nThe City of Yokohama Europe Representative Office. n.d. “The\nReasons Why Yokohama Is Chosen\n(横浜が選ばれる理由).” The City of Yokohama Europe\nRepresentative Office. Accessed February 14, 2023. https://yokohama-city.de/jp/business-opportunities/.\n\n\nThe Nature Conservatory, and AECOM. 2021. “Economic\nAssessment of Heat in the Phoenix\nMetro Area.” https://www.nature.org/content/dam/tnc/nature/en/documents/TNC_EcoHeatAssement_AZ_Report.pdf.\n\n\nUnited Nations Office for Disaster Risk Reduction. n.d. “What Is\nthe Sendai Framework for Disaster\nRisk Reduction?” United Nations\nOffice Fot Disaster Risk Reduction. Accessed February 15, 2023. https://www.undrr.org/implementing-sendai-framework/what-sendai-framework.\n\n\nWadoux, Alexandre MJ-C, Gerard BM Heuvelink, Sytze De Bruin, and Dick J\nBrus. 2021. “Spatial Cross-Validation Is Not the Right Way to\nEvaluate Map Accuracy.” Ecological Modelling 457:\n109692.\n\n\nWang, Chuyuan, Soe W Myint, Zhihua Wang, and Jiyun Song. 2016.\n“Spatio-Temporal Modeling of the Urban Heat Island in the\nPhoenix Metropolitan Area: Land Use Change\nImplications.” Remote Sensing 8 (3): 185.\n\n\nYildirim, Soner. 2020. “Hyperparameter Tuning for\nSupport Vector Machines —\nC and Gamma Parameters.”\nTowards Data Science. https://towardsdatascience.com/hyperparameter-tuning-for-support-vector-machines-c-and-gamma-parameters-6a5097416167.\n\n\nYokohama City Disaster Prevention Council. 2021. “Yokohama\nCity Disaster Prevention\nPlan Earthquake Countermeasures 2021\n(横浜市防災計画震災対策編).” City of Yokohama. https://www.city.yokohama.lg.jp/kurashi/bousai-kyukyu-bohan/bousai-saigai/bosaikeikaku/keikaku/keikakutou/shinsai.files/shinsaitaisaku-all.pdf.\n\n\nZhang, Yujia, Alan T Murray, and BL Turner Ii. 2017. “Optimizing\nGreen Space Locations to Reduce Daytime and Nighttime Urban Heat Island\nEffects in Phoenix, Arizona.”\nLandscape and Urban Planning 165: 162–71."
  }
]